// Code generated by timoni. DO NOT EDIT.

//timoni:generate timoni vendor crd -f https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.40.0/strimzi-crds-0.40.0.yaml

package v1beta2

import "strings"

#KafkaConnect: {
	// APIVersion defines the versioned schema of this representation
	// of an object. Servers should convert recognized schemas to the
	// latest internal value, and may reject unrecognized values.
	// More info:
	// https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	apiVersion: "kafka.strimzi.io/v1beta2"

	// Kind is a string value representing the REST resource this
	// object represents. Servers may infer this from the endpoint
	// the client submits requests to. Cannot be updated. In
	// CamelCase. More info:
	// https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	kind: "KafkaConnect"
	metadata!: {
		name!: strings.MaxRunes(253) & strings.MinRunes(1) & {
			string
		}
		namespace!: strings.MaxRunes(63) & strings.MinRunes(1) & {
			string
		}
		labels?: {
			[string]: string
		}
		annotations?: {
			[string]: string
		}
	}

	// The specification of the Kafka Connect cluster.
	spec!: #KafkaConnectSpec
}

// The specification of the Kafka Connect cluster.
#KafkaConnectSpec: {
	// Authentication configuration for Kafka Connect.
	authentication?: {
		// Link to Kubernetes Secret containing the access token which was
		// obtained from the authorization server.
		accessToken?: {
			// The key under which the secret value is stored in the
			// Kubernetes Secret.
			key: string

			// The name of the Kubernetes Secret containing the secret value.
			secretName: string
		}

		// Configure whether access token should be treated as JWT. This
		// should be set to `false` if the authorization server returns
		// opaque tokens. Defaults to `true`.
		accessTokenIsJwt?: bool

		// OAuth audience to use when authenticating against the
		// authorization server. Some authorization servers require the
		// audience to be explicitly set. The possible values depend on
		// how the authorization server is configured. By default,
		// `audience` is not specified when performing the token endpoint
		// request.
		audience?: string

		// Reference to the `Secret` which holds the certificate and
		// private key pair.
		certificateAndKey?: {
			// The name of the file certificate in the Secret.
			certificate: string

			// The name of the private key in the Secret.
			key: string

			// The name of the Secret containing the certificate.
			secretName: string
		}

		// OAuth Client ID which the Kafka client can use to authenticate
		// against the OAuth server and use the token endpoint URI.
		clientId?: string

		// Link to Kubernetes Secret containing the OAuth client secret
		// which the Kafka client can use to authenticate against the
		// OAuth server and use the token endpoint URI.
		clientSecret?: {
			// The key under which the secret value is stored in the
			// Kubernetes Secret.
			key: string

			// The name of the Kubernetes Secret containing the secret value.
			secretName: string
		}

		// The connect timeout in seconds when connecting to authorization
		// server. If not set, the effective connect timeout is 60
		// seconds.
		connectTimeoutSeconds?: int

		// Enable or disable TLS hostname verification. Default value is
		// `false`.
		disableTlsHostnameVerification?: bool

		// Enable or disable OAuth metrics. Default value is `false`.
		enableMetrics?: bool

		// The maximum number of retries to attempt if an initial HTTP
		// request fails. If not set, the default is to not attempt any
		// retries.
		httpRetries?: int

		// The pause to take before retrying a failed HTTP request. If not
		// set, the default is to not pause at all but to immediately
		// repeat a request.
		httpRetryPauseMs?: int

		// Whether the Accept header should be set in requests to the
		// authorization servers. The default value is `true`.
		includeAcceptHeader?: bool

		// Set or limit time-to-live of the access tokens to the specified
		// number of seconds. This should be set if the authorization
		// server returns opaque tokens.
		maxTokenExpirySeconds?: int

		// Reference to the `Secret` which holds the password.
		passwordSecret?: {
			// The name of the key in the Secret under which the password is
			// stored.
			password: string

			// The name of the Secret containing the password.
			secretName: string
		}

		// The read timeout in seconds when connecting to authorization
		// server. If not set, the effective read timeout is 60 seconds.
		readTimeoutSeconds?: int

		// Link to Kubernetes Secret containing the refresh token which
		// can be used to obtain access token from the authorization
		// server.
		refreshToken?: {
			// The key under which the secret value is stored in the
			// Kubernetes Secret.
			key: string

			// The name of the Kubernetes Secret containing the secret value.
			secretName: string
		}

		// OAuth scope to use when authenticating against the
		// authorization server. Some authorization servers require this
		// to be set. The possible values depend on how authorization
		// server is configured. By default `scope` is not specified when
		// doing the token endpoint request.
		scope?: string

		// Trusted certificates for TLS connection to the OAuth server.
		tlsTrustedCertificates?: [...{
			// The name of the file certificate in the Secret.
			certificate: string

			// The name of the Secret containing the certificate.
			secretName: string
		}]

		// Authorization server token endpoint URI.
		tokenEndpointUri?: string

		// Authentication type. Currently the supported types are `tls`,
		// `scram-sha-256`, `scram-sha-512`, `plain`, and 'oauth'.
		// `scram-sha-256` and `scram-sha-512` types use SASL
		// SCRAM-SHA-256 and SASL SCRAM-SHA-512 Authentication,
		// respectively. `plain` type uses SASL PLAIN Authentication.
		// `oauth` type uses SASL OAUTHBEARER Authentication. The `tls`
		// type uses TLS Client Authentication. The `tls` type is
		// supported only over TLS connections.
		type: "tls" | "scram-sha-256" | "scram-sha-512" | "plain" | "oauth"

		// Username used for the authentication.
		username?: string
	}

	// Bootstrap servers to connect to. This should be given as a
	// comma separated list of _<hostname>_:_<port>_ pairs.
	bootstrapServers: string

	// Configures how the Connect container image should be built.
	// Optional.
	build?: {
		// Configures where should the newly built image be stored.
		// Required.
		output: {
			// Configures additional options which will be passed to the
			// Kaniko executor when building the new Connect image. Allowed
			// options are: --customPlatform, --insecure, --insecure-pull,
			// --insecure-registry, --log-format, --log-timestamp,
			// --registry-mirror, --reproducible, --single-snapshot,
			// --skip-tls-verify, --skip-tls-verify-pull,
			// --skip-tls-verify-registry, --verbosity, --snapshotMode,
			// --use-new-run. These options will be used only on Kubernetes
			// where the Kaniko executor is used. They will be ignored on
			// OpenShift. The options are described in the
			// link:https://github.com/GoogleContainerTools/kaniko[Kaniko
			// GitHub repository^]. Changing this field does not trigger new
			// build of the Kafka Connect image.
			additionalKanikoOptions?: [...string]

			// The name of the image which will be built. Required.
			image: string

			// Container Registry Secret with the credentials for pushing the
			// newly built image.
			pushSecret?: string

			// Output type. Must be either `docker` for pushing the newly
			// build image to Docker compatible registry or `imagestream` for
			// pushing the image to OpenShift ImageStream. Required.
			type: "docker" | "imagestream"
		}

		// List of connector plugins which should be added to the Kafka
		// Connect. Required.
		plugins: [...{
			// List of artifacts which belong to this connector plugin.
			// Required.
			artifacts: [...{
				// Maven artifact id. Applicable to the `maven` artifact type
				// only.
				artifact?: string

				// Name under which the artifact will be stored.
				fileName?: string

				// Maven group id. Applicable to the `maven` artifact type only.
				group?: string

				// By default, connections using TLS are verified to check they
				// are secure. The server certificate used must be valid,
				// trusted, and contain the server name. By setting this option
				// to `true`, all TLS verification is disabled and the artifact
				// will be downloaded, even when the server is considered
				// insecure.
				insecure?: bool

				// Maven repository to download the artifact from. Applicable to
				// the `maven` artifact type only.
				repository?: string

				// SHA512 checksum of the artifact. Optional. If specified, the
				// checksum will be verified while building the new container. If
				// not specified, the downloaded artifact will not be verified.
				// Not applicable to the `maven` artifact type.
				sha512sum?: string

				// Artifact type. Currently, the supported artifact types are
				// `tgz`, `jar`, `zip`, `other` and `maven`.
				type: "jar" | "tgz" | "zip" | "maven" | "other"

				// URL of the artifact which will be downloaded. Strimzi does not
				// do any security scanning of the downloaded artifacts. For
				// security reasons, you should first verify the artifacts
				// manually and configure the checksum verification to make sure
				// the same artifact is used in the automated build. Required for
				// `jar`, `zip`, `tgz` and `other` artifacts. Not applicable to
				// the `maven` artifact type.
				url?: =~"^(https?|ftp)://[-a-zA-Z0-9+&@#/%?=~_|!:,.;]*[-a-zA-Z0-9+&@#/%=~_|]$"

				// Maven version number. Applicable to the `maven` artifact type
				// only.
				version?: string
			}]

			// The unique name of the connector plugin. Will be used to
			// generate the path where the connector artifacts will be
			// stored. The name has to be unique within the KafkaConnect
			// resource. The name has to follow the following pattern:
			// `^[a-z][-_a-z0-9]*[a-z]$`. Required.
			name: =~"^[a-z0-9][-_a-z0-9]*[a-z0-9]$"
		}]

		// CPU and memory resources to reserve for the build.
		resources?: {
			claims?: [...{
				name?: string
			}]
			limits?: {
				...
			}
			requests?: {
				...
			}
		}
	}

	// The image of the init container used for initializing the
	// `client.rack`.
	clientRackInitImage?: string

	// The Kafka Connect configuration. Properties with the following
	// prefixes cannot be set: ssl., sasl., security., listeners,
	// plugin.path, rest., bootstrap.servers,
	// consumer.interceptor.classes, producer.interceptor.classes
	// (with the exception of: ssl.endpoint.identification.algorithm,
	// ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
	config?: {
		...
	}

	// Pass data from Secrets or ConfigMaps to the Kafka Connect pods
	// and use them to configure connectors.
	externalConfiguration?: {
		// Makes data from a Secret or ConfigMap available in the Kafka
		// Connect pods as environment variables.
		env?: [...{
			// Name of the environment variable which will be passed to the
			// Kafka Connect pods. The name of the environment variable
			// cannot start with `KAFKA_` or `STRIMZI_`.
			name: string

			// Value of the environment variable which will be passed to the
			// Kafka Connect pods. It can be passed either as a reference to
			// Secret or ConfigMap field. The field has to specify exactly
			// one Secret or ConfigMap.
			valueFrom: {
				// Reference to a key in a ConfigMap.
				configMapKeyRef?: {
					key?:      string
					name?:     string
					optional?: bool
				}

				// Reference to a key in a Secret.
				secretKeyRef?: {
					key?:      string
					name?:     string
					optional?: bool
				}
			}
		}]

		// Makes data from a Secret or ConfigMap available in the Kafka
		// Connect pods as volumes.
		volumes?: [...{
			// Reference to a key in a ConfigMap. Exactly one Secret or
			// ConfigMap has to be specified.
			configMap?: {
				defaultMode?: int
				items?: [...{
					key?:  string
					mode?: int
					path?: string
				}]
				name?:     string
				optional?: bool
			}

			// Name of the volume which will be added to the Kafka Connect
			// pods.
			name: string

			// Reference to a key in a Secret. Exactly one Secret or ConfigMap
			// has to be specified.
			secret?: {
				defaultMode?: int
				items?: [...{
					key?:  string
					mode?: int
					path?: string
				}]
				optional?:   bool
				secretName?: string
			}
		}]
	}

	// The container image used for Kafka Connect pods. If no image
	// name is explicitly specified, it is determined based on the
	// `spec.version` configuration. The image names are specifically
	// mapped to corresponding versions in the Cluster Operator
	// configuration.
	image?: string
	jmxOptions?: {
		authentication?: {
			// Authentication type. Currently the only supported types are
			// `password`.`password` type creates a username and protected
			// port with no TLS.
			type: "password"
		}
	}

	// JVM Options for pods.
	jvmOptions?: {
		// A map of -XX options to the JVM.
		"-XX"?: {
			[string]: string
		}

		// -Xms option to to the JVM.
		"-Xms"?: =~"^[0-9]+[mMgG]?$"

		// -Xmx option to to the JVM.
		"-Xmx"?: =~"^[0-9]+[mMgG]?$"

		// Specifies whether the Garbage Collection logging is enabled.
		// The default is false.
		gcLoggingEnabled?: bool

		// A map of additional system properties which will be passed
		// using the `-D` option to the JVM.
		javaSystemProperties?: [...{
			// The system property name.
			name?: string

			// The system property value.
			value?: string
		}]
	}

	// Pod liveness checking.
	livenessProbe?: {
		// Minimum consecutive failures for the probe to be considered
		// failed after having succeeded. Defaults to 3. Minimum value is
		// 1.
		failureThreshold?: >=1 & int

		// The initial delay before first the health is first checked.
		// Default to 15 seconds. Minimum value is 0.
		initialDelaySeconds?: >=0 & int

		// How often (in seconds) to perform the probe. Default to 10
		// seconds. Minimum value is 1.
		periodSeconds?: >=1 & int

		// Minimum consecutive successes for the probe to be considered
		// successful after having failed. Defaults to 1. Must be 1 for
		// liveness. Minimum value is 1.
		successThreshold?: >=1 & int

		// The timeout for each attempted health check. Default to 5
		// seconds. Minimum value is 1.
		timeoutSeconds?: >=1 & int
	}

	// Logging configuration for Kafka Connect.
	logging?: {
		// A Map from logger name to logger level.
		loggers?: {
			[string]: string
		}

		// Logging type, must be either 'inline' or 'external'.
		type: "inline" | "external"
		valueFrom?: {
			// Reference to the key in the ConfigMap containing the
			// configuration.
			configMapKeyRef?: {
				key?:      string
				name?:     string
				optional?: bool
			}
		}
	}

	// Metrics configuration.
	metricsConfig?: {
		// Metrics type. Only 'jmxPrometheusExporter' supported currently.
		type: "jmxPrometheusExporter"
		valueFrom: {
			// Reference to the key in the ConfigMap containing the
			// configuration.
			configMapKeyRef?: {
				key?:      string
				name?:     string
				optional?: bool
			}
		}
	}
	rack?: {
		// A key that matches labels assigned to the Kubernetes cluster
		// nodes. The value of the label is used to set a broker's
		// `broker.rack` config, and the `client.rack` config for Kafka
		// Connect or MirrorMaker 2.
		topologyKey: string
	}

	// Pod readiness checking.
	readinessProbe?: {
		// Minimum consecutive failures for the probe to be considered
		// failed after having succeeded. Defaults to 3. Minimum value is
		// 1.
		failureThreshold?: >=1 & int

		// The initial delay before first the health is first checked.
		// Default to 15 seconds. Minimum value is 0.
		initialDelaySeconds?: >=0 & int

		// How often (in seconds) to perform the probe. Default to 10
		// seconds. Minimum value is 1.
		periodSeconds?: >=1 & int

		// Minimum consecutive successes for the probe to be considered
		// successful after having failed. Defaults to 1. Must be 1 for
		// liveness. Minimum value is 1.
		successThreshold?: >=1 & int

		// The timeout for each attempted health check. Default to 5
		// seconds. Minimum value is 1.
		timeoutSeconds?: >=1 & int
	}

	// The number of pods in the Kafka Connect group. Defaults to `3`.
	replicas?: int

	// The maximum limits for CPU and memory resources and the
	// requested initial resources.
	resources?: {
		claims?: [...{
			name?: string
		}]
		limits?: {
			...
		}
		requests?: {
			...
		}
	}

	// Template for Kafka Connect and Kafka Mirror Maker 2 resources.
	// The template allows users to specify how the `Pods`,
	// `Service`, and other services are generated.
	template?: {
		// Template for Kafka Connect API `Service`.
		apiService?: {
			// Specifies the IP Families used by the service. Available
			// options are `IPv4` and `IPv6`. If unspecified, Kubernetes will
			// choose the default value based on the `ipFamilyPolicy`
			// setting.
			ipFamilies?: [..."IPv4" | "IPv6"]

			// Specifies the IP Family Policy used by the service. Available
			// options are `SingleStack`, `PreferDualStack` and
			// `RequireDualStack`. `SingleStack` is for a single IP family.
			// `PreferDualStack` is for two IP families on dual-stack
			// configured clusters or a single IP family on single-stack
			// clusters. `RequireDualStack` fails unless there are two IP
			// families on dual-stack configured clusters. If unspecified,
			// Kubernetes will choose the default value based on the service
			// type.
			ipFamilyPolicy?: "SingleStack" | "PreferDualStack" | "RequireDualStack"

			// Metadata applied to the resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}
		}

		// Template for the Kafka Connect BuildConfig used to build new
		// container images. The BuildConfig is used only on OpenShift.
		buildConfig?: {
			// Metadata to apply to the `PodDisruptionBudgetTemplate`
			// resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}

			// Container Registry Secret with the credentials for pulling the
			// base image.
			pullSecret?: string
		}

		// Template for the Kafka Connect Build container. The build
		// container is used only on Kubernetes.
		buildContainer?: {
			// Environment variables which should be applied to the container.
			env?: [...{
				// The environment variable key.
				name?: string

				// The environment variable value.
				value?: string
			}]

			// Security context for the container.
			securityContext?: {
				allowPrivilegeEscalation?: bool
				capabilities?: {
					add?: [...string]
					drop?: [...string]
				}
				privileged?:             bool
				procMount?:              string
				readOnlyRootFilesystem?: bool
				runAsGroup?:             int
				runAsNonRoot?:           bool
				runAsUser?:              int
				seLinuxOptions?: {
					level?: string
					role?:  string
					type?:  string
					user?:  string
				}
				seccompProfile?: {
					localhostProfile?: string
					type?:             string
				}
				windowsOptions?: {
					gmsaCredentialSpec?:     string
					gmsaCredentialSpecName?: string
					hostProcess?:            bool
					runAsUserName?:          string
				}
			}
		}

		// Template for Kafka Connect Build `Pods`. The build pod is used
		// only on Kubernetes.
		buildPod?: {
			// The pod's affinity rules.
			affinity?: {
				nodeAffinity?: {
					preferredDuringSchedulingIgnoredDuringExecution?: [...{
						preference?: {
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchFields?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
						}
						weight?: int
					}]
					requiredDuringSchedulingIgnoredDuringExecution?: {
						nodeSelectorTerms?: [...{
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchFields?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
						}]
					}
				}
				podAffinity?: {
					preferredDuringSchedulingIgnoredDuringExecution?: [...{
						podAffinityTerm?: {
							labelSelector?: {
								matchExpressions?: [...{
									key?:      string
									operator?: string
									values?: [...string]
								}]
								matchLabels?: {
									[string]: string
								}
							}
							matchLabelKeys?: [...string]
							mismatchLabelKeys?: [...string]
							namespaceSelector?: {
								matchExpressions?: [...{
									key?:      string
									operator?: string
									values?: [...string]
								}]
								matchLabels?: {
									[string]: string
								}
							}
							namespaces?: [...string]
							topologyKey?: string
						}
						weight?: int
					}]
					requiredDuringSchedulingIgnoredDuringExecution?: [...{
						labelSelector?: {
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchLabels?: {
								[string]: string
							}
						}
						matchLabelKeys?: [...string]
						mismatchLabelKeys?: [...string]
						namespaceSelector?: {
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchLabels?: {
								[string]: string
							}
						}
						namespaces?: [...string]
						topologyKey?: string
					}]
				}
				podAntiAffinity?: {
					preferredDuringSchedulingIgnoredDuringExecution?: [...{
						podAffinityTerm?: {
							labelSelector?: {
								matchExpressions?: [...{
									key?:      string
									operator?: string
									values?: [...string]
								}]
								matchLabels?: {
									[string]: string
								}
							}
							matchLabelKeys?: [...string]
							mismatchLabelKeys?: [...string]
							namespaceSelector?: {
								matchExpressions?: [...{
									key?:      string
									operator?: string
									values?: [...string]
								}]
								matchLabels?: {
									[string]: string
								}
							}
							namespaces?: [...string]
							topologyKey?: string
						}
						weight?: int
					}]
					requiredDuringSchedulingIgnoredDuringExecution?: [...{
						labelSelector?: {
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchLabels?: {
								[string]: string
							}
						}
						matchLabelKeys?: [...string]
						mismatchLabelKeys?: [...string]
						namespaceSelector?: {
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchLabels?: {
								[string]: string
							}
						}
						namespaces?: [...string]
						topologyKey?: string
					}]
				}
			}

			// Indicates whether information about services should be injected
			// into Pod's environment variables.
			enableServiceLinks?: bool

			// The pod's HostAliases. HostAliases is an optional list of hosts
			// and IPs that will be injected into the Pod's hosts file if
			// specified.
			hostAliases?: [...{
				hostnames?: [...string]
				ip?: string
			}]

			// List of references to secrets in the same namespace to use for
			// pulling any of the images used by this Pod. When the
			// `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster
			// Operator and the `imagePullSecrets` option are specified, only
			// the `imagePullSecrets` variable is used and the
			// `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
			imagePullSecrets?: [...{
				name?: string
			}]

			// Metadata applied to the resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}

			// The name of the priority class used to assign priority to the
			// pods.
			priorityClassName?: string

			// The name of the scheduler used to dispatch this `Pod`. If not
			// specified, the default scheduler will be used.
			schedulerName?: string

			// Configures pod-level security attributes and common container
			// settings.
			securityContext?: {
				fsGroup?:             int
				fsGroupChangePolicy?: string
				runAsGroup?:          int
				runAsNonRoot?:        bool
				runAsUser?:           int
				seLinuxOptions?: {
					level?: string
					role?:  string
					type?:  string
					user?:  string
				}
				seccompProfile?: {
					localhostProfile?: string
					type?:             string
				}
				supplementalGroups?: [...int]
				sysctls?: [...{
					name?:  string
					value?: string
				}]
				windowsOptions?: {
					gmsaCredentialSpec?:     string
					gmsaCredentialSpecName?: string
					hostProcess?:            bool
					runAsUserName?:          string
				}
			}

			// The grace period is the duration in seconds after the processes
			// running in the pod are sent a termination signal, and the time
			// when the processes are forcibly halted with a kill signal. Set
			// this value to longer than the expected cleanup time for your
			// process. Value must be a non-negative integer. A zero value
			// indicates delete immediately. You might need to increase the
			// grace period for very large Kafka clusters, so that the Kafka
			// brokers have enough time to transfer their work to another
			// broker before they are terminated. Defaults to 30 seconds.
			terminationGracePeriodSeconds?: >=0 & int

			// Defines the total amount (for example `1Gi`) of local storage
			// required for temporary EmptyDir volume (`/tmp`). Default value
			// is `5Mi`.
			tmpDirSizeLimit?: =~"^([0-9.]+)([eEinumkKMGTP]*[-+]?[0-9]*)$"

			// The pod's tolerations.
			tolerations?: [...{
				effect?:            string
				key?:               string
				operator?:          string
				tolerationSeconds?: int
				value?:             string
			}]

			// The pod's topology spread constraints.
			topologySpreadConstraints?: [...{
				labelSelector?: {
					matchExpressions?: [...{
						key?:      string
						operator?: string
						values?: [...string]
					}]
					matchLabels?: {
						[string]: string
					}
				}
				matchLabelKeys?: [...string]
				maxSkew?:            int
				minDomains?:         int
				nodeAffinityPolicy?: string
				nodeTaintsPolicy?:   string
				topologyKey?:        string
				whenUnsatisfiable?:  string
			}]
		}
		buildServiceAccount?: {
			// Metadata applied to the resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}
		}
		clusterRoleBinding?: {
			// Metadata applied to the resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}
		}

		// Template for the Kafka Connect container.
		connectContainer?: {
			// Environment variables which should be applied to the container.
			env?: [...{
				// The environment variable key.
				name?: string

				// The environment variable value.
				value?: string
			}]

			// Security context for the container.
			securityContext?: {
				allowPrivilegeEscalation?: bool
				capabilities?: {
					add?: [...string]
					drop?: [...string]
				}
				privileged?:             bool
				procMount?:              string
				readOnlyRootFilesystem?: bool
				runAsGroup?:             int
				runAsNonRoot?:           bool
				runAsUser?:              int
				seLinuxOptions?: {
					level?: string
					role?:  string
					type?:  string
					user?:  string
				}
				seccompProfile?: {
					localhostProfile?: string
					type?:             string
				}
				windowsOptions?: {
					gmsaCredentialSpec?:     string
					gmsaCredentialSpecName?: string
					hostProcess?:            bool
					runAsUserName?:          string
				}
			}
		}

		// Template for Kafka Connect `Deployment`.
		deployment?: {
			// Pod replacement strategy for deployment configuration changes.
			// Valid values are `RollingUpdate` and `Recreate`. Defaults to
			// `RollingUpdate`.
			deploymentStrategy?: "RollingUpdate" | "Recreate"

			// Metadata applied to the resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}
		}

		// Template for Kafka Connect headless `Service`.
		headlessService?: {
			// Specifies the IP Families used by the service. Available
			// options are `IPv4` and `IPv6`. If unspecified, Kubernetes will
			// choose the default value based on the `ipFamilyPolicy`
			// setting.
			ipFamilies?: [..."IPv4" | "IPv6"]

			// Specifies the IP Family Policy used by the service. Available
			// options are `SingleStack`, `PreferDualStack` and
			// `RequireDualStack`. `SingleStack` is for a single IP family.
			// `PreferDualStack` is for two IP families on dual-stack
			// configured clusters or a single IP family on single-stack
			// clusters. `RequireDualStack` fails unless there are two IP
			// families on dual-stack configured clusters. If unspecified,
			// Kubernetes will choose the default value based on the service
			// type.
			ipFamilyPolicy?: "SingleStack" | "PreferDualStack" | "RequireDualStack"

			// Metadata applied to the resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}
		}

		// Template for the Kafka init container.
		initContainer?: {
			// Environment variables which should be applied to the container.
			env?: [...{
				// The environment variable key.
				name?: string

				// The environment variable value.
				value?: string
			}]

			// Security context for the container.
			securityContext?: {
				allowPrivilegeEscalation?: bool
				capabilities?: {
					add?: [...string]
					drop?: [...string]
				}
				privileged?:             bool
				procMount?:              string
				readOnlyRootFilesystem?: bool
				runAsGroup?:             int
				runAsNonRoot?:           bool
				runAsUser?:              int
				seLinuxOptions?: {
					level?: string
					role?:  string
					type?:  string
					user?:  string
				}
				seccompProfile?: {
					localhostProfile?: string
					type?:             string
				}
				windowsOptions?: {
					gmsaCredentialSpec?:     string
					gmsaCredentialSpecName?: string
					hostProcess?:            bool
					runAsUserName?:          string
				}
			}
		}
		jmxSecret?: {
			// Metadata applied to the resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}
		}

		// Template for Kafka Connect `Pods`.
		pod?: {
			// The pod's affinity rules.
			affinity?: {
				nodeAffinity?: {
					preferredDuringSchedulingIgnoredDuringExecution?: [...{
						preference?: {
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchFields?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
						}
						weight?: int
					}]
					requiredDuringSchedulingIgnoredDuringExecution?: {
						nodeSelectorTerms?: [...{
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchFields?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
						}]
					}
				}
				podAffinity?: {
					preferredDuringSchedulingIgnoredDuringExecution?: [...{
						podAffinityTerm?: {
							labelSelector?: {
								matchExpressions?: [...{
									key?:      string
									operator?: string
									values?: [...string]
								}]
								matchLabels?: {
									[string]: string
								}
							}
							matchLabelKeys?: [...string]
							mismatchLabelKeys?: [...string]
							namespaceSelector?: {
								matchExpressions?: [...{
									key?:      string
									operator?: string
									values?: [...string]
								}]
								matchLabels?: {
									[string]: string
								}
							}
							namespaces?: [...string]
							topologyKey?: string
						}
						weight?: int
					}]
					requiredDuringSchedulingIgnoredDuringExecution?: [...{
						labelSelector?: {
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchLabels?: {
								[string]: string
							}
						}
						matchLabelKeys?: [...string]
						mismatchLabelKeys?: [...string]
						namespaceSelector?: {
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchLabels?: {
								[string]: string
							}
						}
						namespaces?: [...string]
						topologyKey?: string
					}]
				}
				podAntiAffinity?: {
					preferredDuringSchedulingIgnoredDuringExecution?: [...{
						podAffinityTerm?: {
							labelSelector?: {
								matchExpressions?: [...{
									key?:      string
									operator?: string
									values?: [...string]
								}]
								matchLabels?: {
									[string]: string
								}
							}
							matchLabelKeys?: [...string]
							mismatchLabelKeys?: [...string]
							namespaceSelector?: {
								matchExpressions?: [...{
									key?:      string
									operator?: string
									values?: [...string]
								}]
								matchLabels?: {
									[string]: string
								}
							}
							namespaces?: [...string]
							topologyKey?: string
						}
						weight?: int
					}]
					requiredDuringSchedulingIgnoredDuringExecution?: [...{
						labelSelector?: {
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchLabels?: {
								[string]: string
							}
						}
						matchLabelKeys?: [...string]
						mismatchLabelKeys?: [...string]
						namespaceSelector?: {
							matchExpressions?: [...{
								key?:      string
								operator?: string
								values?: [...string]
							}]
							matchLabels?: {
								[string]: string
							}
						}
						namespaces?: [...string]
						topologyKey?: string
					}]
				}
			}

			// Indicates whether information about services should be injected
			// into Pod's environment variables.
			enableServiceLinks?: bool

			// The pod's HostAliases. HostAliases is an optional list of hosts
			// and IPs that will be injected into the Pod's hosts file if
			// specified.
			hostAliases?: [...{
				hostnames?: [...string]
				ip?: string
			}]

			// List of references to secrets in the same namespace to use for
			// pulling any of the images used by this Pod. When the
			// `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster
			// Operator and the `imagePullSecrets` option are specified, only
			// the `imagePullSecrets` variable is used and the
			// `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
			imagePullSecrets?: [...{
				name?: string
			}]

			// Metadata applied to the resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}

			// The name of the priority class used to assign priority to the
			// pods.
			priorityClassName?: string

			// The name of the scheduler used to dispatch this `Pod`. If not
			// specified, the default scheduler will be used.
			schedulerName?: string

			// Configures pod-level security attributes and common container
			// settings.
			securityContext?: {
				fsGroup?:             int
				fsGroupChangePolicy?: string
				runAsGroup?:          int
				runAsNonRoot?:        bool
				runAsUser?:           int
				seLinuxOptions?: {
					level?: string
					role?:  string
					type?:  string
					user?:  string
				}
				seccompProfile?: {
					localhostProfile?: string
					type?:             string
				}
				supplementalGroups?: [...int]
				sysctls?: [...{
					name?:  string
					value?: string
				}]
				windowsOptions?: {
					gmsaCredentialSpec?:     string
					gmsaCredentialSpecName?: string
					hostProcess?:            bool
					runAsUserName?:          string
				}
			}

			// The grace period is the duration in seconds after the processes
			// running in the pod are sent a termination signal, and the time
			// when the processes are forcibly halted with a kill signal. Set
			// this value to longer than the expected cleanup time for your
			// process. Value must be a non-negative integer. A zero value
			// indicates delete immediately. You might need to increase the
			// grace period for very large Kafka clusters, so that the Kafka
			// brokers have enough time to transfer their work to another
			// broker before they are terminated. Defaults to 30 seconds.
			terminationGracePeriodSeconds?: >=0 & int

			// Defines the total amount (for example `1Gi`) of local storage
			// required for temporary EmptyDir volume (`/tmp`). Default value
			// is `5Mi`.
			tmpDirSizeLimit?: =~"^([0-9.]+)([eEinumkKMGTP]*[-+]?[0-9]*)$"

			// The pod's tolerations.
			tolerations?: [...{
				effect?:            string
				key?:               string
				operator?:          string
				tolerationSeconds?: int
				value?:             string
			}]

			// The pod's topology spread constraints.
			topologySpreadConstraints?: [...{
				labelSelector?: {
					matchExpressions?: [...{
						key?:      string
						operator?: string
						values?: [...string]
					}]
					matchLabels?: {
						[string]: string
					}
				}
				matchLabelKeys?: [...string]
				maxSkew?:            int
				minDomains?:         int
				nodeAffinityPolicy?: string
				nodeTaintsPolicy?:   string
				topologyKey?:        string
				whenUnsatisfiable?:  string
			}]
		}

		// Template for Kafka Connect `PodDisruptionBudget`.
		podDisruptionBudget?: {
			// Maximum number of unavailable pods to allow automatic Pod
			// eviction. A Pod eviction is allowed when the `maxUnavailable`
			// number of pods or fewer are unavailable after the eviction.
			// Setting this value to 0 prevents all voluntary evictions, so
			// the pods must be evicted manually. Defaults to 1.
			maxUnavailable?: >=0 & int

			// Metadata to apply to the `PodDisruptionBudgetTemplate`
			// resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}
		}
		podSet?: {
			// Metadata applied to the resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}
		}
		serviceAccount?: {
			// Metadata applied to the resource.
			metadata?: {
				// Annotations added to the Kubernetes resource.
				annotations?: {
					[string]: string
				}

				// Labels added to the Kubernetes resource.
				labels?: {
					[string]: string
				}
			}
		}
	}
	tls?: {
		// Trusted certificates for TLS connection.
		trustedCertificates?: [...{
			// The name of the file certificate in the Secret.
			certificate: string

			// The name of the Secret containing the certificate.
			secretName: string
		}]
	}
	tracing?: {
		// Type of the tracing used. Currently the only supported type is
		// `opentelemetry` for OpenTelemetry tracing. As of Strimzi
		// 0.37.0, `jaeger` type is not supported anymore and this option
		// is ignored.
		type: "jaeger" | "opentelemetry"
	}

	// The Kafka Connect version. Defaults to the latest version.
	// Consult the user documentation to understand the process
	// required to upgrade or downgrade the version.
	version?: string
}
